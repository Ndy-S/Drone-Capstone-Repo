{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All necessary dependencies (import)\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "with open('./sentiment_models/model_architecture.json', 'r') as json_file:\n",
    "    model_architecture = json_file.read()\n",
    "\n",
    "model = model_from_json(model_architecture)\n",
    "\n",
    "# Model Weights\n",
    "model.load_weights('./sentiment_models/model_weights.h5')\n",
    "\n",
    "# Tokenizer Words\n",
    "with open('./sentiment_models/tokenizer.pickle', 'rb') as tokenizer_file:\n",
    "    tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "# Load Stop-Words\n",
    "with open(\"./sentiment_models/stopwords.txt\", \"r\") as my_file:\n",
    "    data = my_file.read()\n",
    "\n",
    "stopwords = data.split(\"\\n\")\n",
    "\n",
    "# Initialize stemmer\n",
    "stemmer = StemmerFactory().create_stemmer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "vocab_size = 5000\n",
    "max_length = 120\n",
    "oov_tok = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing steps (removing symbols, numbers, converting emojis, stemming, etc.)\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = text.strip()\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub(r'[\\u2070-\\u209F\\u00B2-\\u00B3\\u00B9-\\u00BF\\u02B0-\\u036F\\u1AB0-\\u1AFF\\u2090-\\u2094]+', '', text)\n",
    "    text = emoji.demojize(text)\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n",
    "    text = text.strip()\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\u0000-\\u007F\\uD800-\\uDBFF\\uDC00-\\uDFFF]+', '', text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    no_words = [w for w in words if w not in stopwords]\n",
    "    text = \" \".join(no_words)\n",
    "    text = stemmer.stem(text)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function \n",
    "def predict_sentiment(input_text):\n",
    "    preprocessed_input_text = preprocess_text(input_text)\n",
    "\n",
    "    input_sequence = pad_sequences(tokenizer.texts_to_sequences([preprocessed_input_text]), maxlen=max_length)\n",
    "    sentiment_score = (model.predict(input_sequence) * 5)\n",
    "\n",
    "    return sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n",
      "[[4.4764047]]\n"
     ]
    }
   ],
   "source": [
    "# Test predicting (0-2.5 (Negative), 2.5-5(Positive))\n",
    "input_text = predict_sentiment(\"bagus banget pelayanannya, mana 24 jam lagi\")\n",
    "print(input_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
